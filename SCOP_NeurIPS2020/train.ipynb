{"cells": [{"metadata": {"trusted": false}, "cell_type": "code", "source": "\n\nfrom __future__ import division\n\n\nimport os, sys, shutil, time, random\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\nimport torchvision.datasets as dset \nimport torchvision.transforms as transforms\nimport time\nimport moxing as mox\nimport math\nimport numpy as np\nimport pickle\nfrom scipy.spatial import distance\nimport pdb\nimport copy\nfrom torch.nn.parameter import Parameter\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nmox.file.shift('os','mox')\n\nos.chdir('./SCOP_NeurIPS2020/')\nfrom utils import AverageMeter, RecorderMeter, time_string, convert_secs2time, timing\nimport models\nfrom models import resnet_imagenet, generator_cifar,generator_imagenet\nfrom pruning_modules import Kf_Conv2d,Masked_Conv2d_bn,Pruned_Conv2d_bn1,Pruned_Conv2d_bn_middle,Pruned_Conv2d_bn2\n\n\nparser = argparse.ArgumentParser(description='SCOP',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument('--data_path', type=str, default='/cache/tyh/cifar10/',help='Path to dataset')\nparser.add_argument('--dataset', type=str,default='imagenet', choices=['cifar10','imagenet'])\nparser.add_argument('--arch',  default='resnet50')\n# Optimization options\n\nparser.add_argument('--batch_size', type=int, default=1024, help='Batch size.')\nparser.add_argument('--batch_size_kf', type=int, default=512, help='Batch size.')\n\nparser.add_argument('--epochs', type=int, default=20, help='Number of epochs to train.')\nparser.add_argument('--learning_rate', type=float, default=0.004, help='The Learning Rate.')\n\nparser.add_argument('--momentum', type=float, default=0.9, help='Momentum.')\nparser.add_argument('--decay', type=float, default=0.0001, help='Weight decay (L2 penalty).')\n\nparser.add_argument('--print_freq', default=200, type=int, metavar='N', help='print frequency (default: 200)')\nparser.add_argument('--save_path', type=str, default='./tmp/', help='Folder to save checkpoints and log.')\n\nparser.add_argument('--evaluate',type=int,default=1, help='evaluate model on validation set')\n\nparser.add_argument('--ngpu', type=int, default=1)\nparser.add_argument('--workers', type=int, default=2, help='number of data loading workers (default: 2)')\n\nparser.add_argument('--manualSeed', type=int, help='manual seed')\n\n\nparser.add_argument('--prune_rate', type=float, default=0.4, help='the reducing ratio of pruning based on knockoff')\n\n\nparser.add_argument('--epochs_ft', type=int, default=120)\nparser.add_argument('--lr_ft', type=float, default=0.2, help='The Learning Rate.')\n\nparser.add_argument('--pretrain_path', default='', type=str, help='..path of pre-trained model')\n\n\n\n\n\nargs,unparsed = parser.parse_known_args()\n\n\n\nargs.use_cuda = args.ngpu > 0 and torch.cuda.is_available()\n\nif args.manualSeed is None:\n    args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif args.use_cuda:\n    torch.cuda.manual_seed_all(args.manualSeed)\ncudnn.benchmark = True\n\n\nif args.dataset=='imagenet':\n    args.workers=16", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "INFO:root:Using MoXing-v1.17.3-\nINFO:root:Using OBS-Python-SDK-3.20.7\n", "name": "stderr"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "def train(train_loader, model, criterion, optimizer, epoch, log):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if args.use_cuda:\n            target = target.cuda(async=True)\n            input = input.cuda()\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data.item(), input.size(0))\n        top1.update(prec1.item(), input.size(0))\n        top5.update(prec5.item(), input.size(0))\n\n    \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print('  Epoch: [{:03d}][{:03d}/{:03d}]   '\n                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})   '\n                      'Data {data_time.val:.3f} ({data_time.avg:.3f})   '\n                      'Loss {loss.val:.4f} ({loss.avg:.4f})   '\n                      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})   '\n                      'Prec@5 {top5.val:.3f} ({top5.avg:.3f})   '.format(\n                epoch, i, len(train_loader), batch_time=batch_time,\n                data_time=data_time, loss=losses, top1=top1, top5=top5) + time_string())\n    print(\n        '  **Train** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}'.format(top1=top1, top5=top5,\n                                                                                              error1=100 - top1.avg))\n    return top1.avg, losses.avg\n\n\ndef validate(val_loader, model, criterion, log):\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n\n    model.eval()\n\n    for i, (input, target) in enumerate(val_loader):\n        if args.use_cuda:\n            target = target.cuda(async=True)\n            input = input.cuda()\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        with torch.no_grad():\n            output = model(input_var)\n            loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data.item(), input.size(0))\n        top1.update(prec1.item(), input.size(0))\n        top5.update(prec5.item(), input.size(0))\n\n    print('  **Test** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}'.format(top1=top1, \n                                                                                                   top5=top5,error1=100 - top1.avg))\n\n    return top1.avg, top5.avg, losses.avg\n\n\ndef save_checkpoint(state, is_best, save_path, filename):\n    filename = os.path.join(save_path, filename)\n    torch.save(state, filename)\n    if is_best:\n        bestname = os.path.join(save_path, 'model_best.pth.tar')\n        shutil.copyfile(filename, bestname)\n\n\ndef adjust_learning_rate(optimizer, epoch, lr_init):\n    lr = lr_init * (0 + (1 - 0) * (1 + math.cos(float(epoch) / args.epochs_ft * math.pi)) * 1/2)\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n    return lr\n\ndef accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\ndef save_obj(obj, name):\n    with open('obj/' + name + '.pkl', 'wb') as f:\n        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n\n\ndef load_obj(name):\n    with open('obj/' + name + '.pkl', 'rb') as f:\n        return pickle.load(f)\n\n\n", "execution_count": 4, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "\nif not os.path.isdir(args.save_path):\n    os.makedirs(args.save_path)\nlog =None\n\n# Init dataset\nif not os.path.isdir(args.data_path):\n    os.makedirs(args.data_path)\n\nif args.dataset == 'cifar10':\n    mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n    std = [x / 255 for x in [63.0, 62.1, 66.7]]\nelif args.dataset == 'cifar100':\n    mean = [x / 255 for x in [129.3, 124.1, 112.4]]\n    std = [x / 255 for x in [68.2, 65.4, 70.4]]\nelif args.dataset=='imagenet':\n    normalize_imgnet = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n    \nelse:\n    assert False, \"Unknow dataset : {}\".format(args.dataset)\nif args.dataset=='imagenet':\n    pass\nelse:\n    train_transform = transforms.Compose(\n        [transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(),\n         transforms.Normalize(mean, std)])\n    test_transform = transforms.Compose(\n        [transforms.ToTensor(), transforms.Normalize(mean, std)])\n\nif args.dataset == 'cifar10':\n    train_data = dset.CIFAR10(args.data_path, train=True, transform=train_transform, download=True)\n    train_data_test = dset.CIFAR10(args.data_path, train=True, transform=test_transform, download=True)\n    \n    test_data = dset.CIFAR10(args.data_path, train=False, transform=test_transform, download=True)\n    num_classes = 10\nelif args.dataset == 'imagenet':\n    \n    train_data = dset.ImageFolder(os.path.join(args.data_path, 'train'),transforms.Compose([\n        transforms.RandomSizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        normalize_imgnet,\n    ]))\n    train_data_test = dset.ImageFolder(os.path.join(args.data_path, 'train'),transforms.Compose([\n        transforms.Scale(256), \n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        normalize_imgnet,\n    ]))\n    \n    test_data=dset.ImageFolder(os.path.join(args.data_path, 'val'), transforms.Compose([\n        transforms.Scale(256), \n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        normalize_imgnet,\n    ]))\n        \nelse:\n    assert False, 'Do not support dataset : {}'.format(args.dataset)\n\n    \n    \n#args.batch_size=12    \ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True,\n                                           num_workers=args.workers, pin_memory=True)\ntrain_loader_kf = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size_kf, shuffle=True,\n                                           num_workers=args.workers, pin_memory=True)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=args.batch_size, shuffle=False,\n                                          num_workers=args.workers, pin_memory=True)\n\n\n\n\n\n", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "Files already downloaded and verified\nFiles already downloaded and verified\nFiles already downloaded and verified\n", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "if args.dataset=='cifar10':\n    netG=generator_cifar.Generator(dim=64)\n    netG=torch.nn.DataParallel(netG, device_ids=list(range(args.ngpu))).cuda() \n    netG.load_state_dict(torch.load(os.path.join(args.pretrain_path,'netG_cifar.pth'))) \nelif args.dataset=='imagenet':\n    netG=generator_imagenet.ResNetGenerator(64, 128, 4,activation=F.relu, num_classes=0, distribution='normal')\n    netG=torch.nn.DataParallel(netG, device_ids=list(range(args.ngpu))).cuda()  \n    netG.module.load_state_dict(torch.load(os.path.join(args.pretrain_path,'netG_imagenet.pth.tar'))['model'])", "execution_count": 6, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "def train_with_kf(train_loader, model, criterion, optimizer, epoch, log,kfclass):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    # switch to train mode\n    model.train()\n    \n    \n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        \n        if input.shape[0]%(args.ngpu)!=0: \n            continue\n        \n        if args.use_cuda:\n            target = target.cuda()\n            input = input.cuda()\n        \n        data_time.update(time.time() - end)\n        \n        if args.dataset=='cifar10':\n            with torch.no_grad():\n                kf_input=kfclass(torch.randn(input.shape[0], 128).cuda())\n        elif args.dataset=='imagenet':\n            with torch.no_grad():\n                kf_input=kfclass(torch.empty(input.shape[0], 128, dtype=torch.float32).normal_().cuda())\n                kf_input=F.interpolate(kf_input,size=224)\n        \n        input_list=[]\n        num_pgpu=input.shape[0]//args.ngpu\n        for igpu in range(args.ngpu):\n            input_list.append(torch.cat([input[igpu*num_pgpu:(igpu+1)*num_pgpu],kf_input[igpu*num_pgpu:(igpu+1)*num_pgpu]],dim=0))\n        input=torch.cat(input_list,dim=0)        \n\n\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n\n        \n        output = model(input_var)\n        output=output[:(output.shape[0]//2)]\n        \n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data.item(), input.size(0))\n        top1.update(prec1.item(), input.size(0))\n        top5.update(prec5.item(), input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        for module in net.modules():\n            if isinstance(module,Kf_Conv2d):\n                module.kfscale.data.clamp_(min=0,max=1) \n        \n        \n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print('  Epoch: [{:03d}][{:03d}/{:03d}]   '\n                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})   '\n                      'Data {data_time.val:.3f} ({data_time.avg:.3f})   '\n                      'Loss {loss.val:.4f} ({loss.avg:.4f})   '\n                      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})   '\n                      'Prec@5 {top5.val:.3f} ({top5.avg:.3f})   '.format(\n                epoch, i, len(train_loader), batch_time=batch_time,\n                data_time=data_time, loss=losses, top1=top1, top5=top5) + time_string())\n    print(\n        '  **Train** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}'.format(top1=top1, top5=top5,\n                                                                                              error1=100 - top1.avg),\n        log)\n    return top1.avg, losses.avg\n", "execution_count": 7, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "print(\"=> creating model '{}'\".format(args.arch))\n\n\nif args.dataset=='imagenet':    \n   \n    if args.arch=='resnet101':\n        net=resnet_imagenet.resnet101()\n    elif args.arch=='resnet50':\n        net=resnet_imagenet.resnet50()\n    elif args.arch=='resnet34':\n        net=resnet_imagenet.resnet34()\n    elif args.arch=='resnet18':\n        net=resnet_imagenet.resnet18()\nelse:\n    if args.arch=='resnet110':\n        net=models.resnet110(num_classes=10)\n    elif args.arch=='resnet56':\n        net=models.resnet56(num_classes=10)\n    elif args.arch=='resnet32':\n        net=models.resnet32(num_classes=10)\n    elif args.arch=='resnet20':\n        net=models.resnet20(num_classes=10)\n        \n\nif args.dataset=='imagenet':\n  \n    if args.arch=='resnet101':\n        state_dict = torch.load(os.path.join(args.pretrain_path,'resnet101-5d3b4d8f.pth'))       \n    elif args.arch=='resnet50':\n        state_dict = torch.load(os.path.join(args.pretrain_path,'resnet50-19c8e357.pth'))\n    elif args.arch=='resnet34':\n        state_dict = torch.load(os.path.join(args.pretrain_path,'resnet34-333f7ec4.pth'))\n    elif args.arch=='resnet18':\n        state_dict = torch.load(os.path.join(args.pretrain_path,'resnet18-5c106cde.pth'))\n\n    from collections import OrderedDict\n    new_state_dict = OrderedDict()\n    for k, v in state_dict.items():\n        if k=='conv1.weight':\n            new_state_dict['conv1_7x7.weight'] = v\n        else:\n            new_state_dict[k] = v    \n    net.load_state_dict(new_state_dict)         \n\nnet = torch.nn.DataParallel(net, device_ids=list(range(args.ngpu)))\n\nif args.dataset!='imagenet':\n    if args.arch=='resnet110':\n        pretrain = torch.load(os.path.join(args.pretrain_path,'cifar_pretrained_nets/','resnet110_multi_step.pth.tar'))\n    elif args.arch=='resnet56':\n        pretrain = torch.load(os.path.join(args.pretrain_path,'cifar_pretrained_nets/','resnet56_multi_step.pth.tar'))\n    elif args.arch=='resnet32':\n        pretrain = torch.load(os.path.join(args.pretrain_path,'cifar_pretrained_nets/','resnet32_multi_step.pth.tar'))\n    elif args.arch=='resnet20':\n        pretrain = torch.load(os.path.join(args.pretrain_path,'cifar_pretrained_nets/','resnet20_multi_step.pth.tar'))\n    net.load_state_dict(pretrain['state_dict'].state_dict())\n\n\n\n\n\n\n\n\n", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "=> creating model 'resnet56'\nCifarResNet : Depth : 56 , Layers for each block : 9\n", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "net=net.cpu()", "execution_count": 9, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "if args.dataset=='imagenet':\n    def transform_conv( net):\n  \n        def _inject(modules):\n            keys = list(modules.keys())\n            #print(keys)\n            for ik, k in enumerate(keys):\n                if isinstance(modules[k], nn.Conv2d): \n \n                    if k!='0' and k!='conv1_7x7': \n                      \n                        modules[k] = Kf_Conv2d(modules[k],modules[keys[ik+1]])\n                        modules[keys[ik+1]]=nn.Sequential() \n                elif (not isinstance(modules[k], Kf_Conv2d)) and len(modules[k]._modules) > 0: \n                    _inject(modules[k]._modules)\n        _inject(net._modules)\nelse:    \n    def transform_conv( net):\n\n        def _inject(modules):\n            keys = list(modules.keys())\n          \n            for ik, k in enumerate(keys):\n                if isinstance(modules[k], nn.Conv2d): \n                    if k!='0' and k!='conv_1_3x3': \n                       \n                        modules[k] = Kf_Conv2d(modules[k],modules[keys[ik+1]])\n                        modules[keys[ik+1]]=nn.Sequential() \n                elif (not isinstance(modules[k], Kf_Conv2d)) and len(modules[k]._modules) > 0: \n                    _inject(modules[k]._modules)\n        _inject(net._modules)\ntransform_conv(net) ", "execution_count": 10, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "kfconv_list=[]\nfor module in net.modules():\n    if isinstance(module,Kf_Conv2d):\n        kfconv_list.append(module)", "execution_count": 11, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "kfscale_list=[[] for _ in range(len(kfconv_list))]", "execution_count": 12, "outputs": []}, {"metadata": {"scrolled": true, "trusted": false}, "cell_type": "code", "source": "net=net.cuda()\n\ncriterion = torch.nn.CrossEntropyLoss().cuda()\nrecorder = RecorderMeter(args.epochs)\n\n\nfor param in net.parameters(): \n    param.requires_grad=False\nfor module in net.modules():\n    if isinstance(module,Kf_Conv2d):\n        module.kfscale.requires_grad=True\n    \n        \noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=args.learning_rate, betas=(0.5, 0.9))\n\n\nstart_time = time.time()\nepoch_time = AverageMeter()\n\n\nnetG.eval()\nfor epoch in range(0, args.epochs):\n    current_learning_rate =args.learning_rate\n    need_hour, need_mins, need_secs = convert_secs2time(epoch_time.avg * (args.epochs - epoch))\n    need_time = '[Need: {:02d}:{:02d}:{:02d}]'.format(need_hour, need_mins, need_secs)\n\n    print(\n        '\\n==>>{:s} [Epoch={:03d}/{:03d}] {:s} [learning_rate={:6.4f}]'.format(time_string(), epoch, args.epochs,\n        need_time, current_learning_rate) + ' [Best : Accuracy={:.2f}, Error={:.2f}]'.format(recorder.max_accuracy(False),\n                                                           100 - recorder.max_accuracy(False)))\n\n    train_acc, train_los =train_with_kf(train_loader_kf, net, criterion, optimizer, epoch, log,kfclass=netG)\n\n    \n    for ikf in range(len(kfconv_list)):\n        kfscale_list[ikf].append(kfconv_list[ikf].kfscale.data.clone().cpu())\n\n\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n    \nfor param in net.parameters():\n    param.requires_grad=True ", "execution_count": null, "outputs": [{"output_type": "stream", "text": "\n==>>[2020-10-05 16:49:46] [Epoch=000/050] [Need: 00:00:00] [learning_rate=0.0100] [Best : Accuracy=0.00, Error=100.00]\n  Epoch: [000][000/391]   Time 0.433 (0.433)   Data 0.163 (0.163)   Loss 5.7038 (5.7038)   Prec@1 8.594 (8.594)   Prec@5 50.781 (50.781)   [2020-10-05 16:49:46]\n  Epoch: [000][200/391]   Time 0.092 (0.090)   Data 0.016 (0.016)   Loss 0.0194 (1.6397)   Prec@1 99.219 (67.996)   Prec@5 100.000 (86.734)   [2020-10-05 16:50:04]\n  **Train** Prec@1 83.234 Prec@5 93.174 Error@1 16.766 None\n\n==>>[2020-10-05 16:50:21] [Epoch=001/050] [Need: 00:28:39] [learning_rate=0.0100] [Best : Accuracy=0.00, Error=100.00]\n  Epoch: [001][000/391]   Time 0.236 (0.236)   Data 0.124 (0.124)   Loss 0.0028 (0.0028)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2020-10-05 16:50:21]\n  Epoch: [001][200/391]   Time 0.088 (0.090)   Data 0.016 (0.015)   Loss 0.0085 (0.0112)   Prec@1 100.000 (99.708)   Prec@5 100.000 (100.000)   [2020-10-05 16:50:39]\n  **Train** Prec@1 99.650 Prec@5 100.000 Error@1 0.350 None\n\n==>>[2020-10-05 16:50:56] [Epoch=002/050] [Need: 00:27:56] [learning_rate=0.0100] [Best : Accuracy=0.00, Error=100.00]\n  Epoch: [002][000/391]   Time 0.199 (0.199)   Data 0.120 (0.120)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2020-10-05 16:50:56]\n  Epoch: [002][200/391]   Time 0.087 (0.088)   Data 0.017 (0.015)   Loss 0.0060 (0.0125)   Prec@1 100.000 (99.604)   Prec@5 100.000 (100.000)   [2020-10-05 16:51:14]\n  **Train** Prec@1 99.644 Prec@5 100.000 Error@1 0.356 None\n\n==>>[2020-10-05 16:51:30] [Epoch=003/050] [Need: 00:27:12] [learning_rate=0.0100] [Best : Accuracy=0.00, Error=100.00]\n  Epoch: [003][000/391]   Time 0.209 (0.209)   Data 0.130 (0.130)   Loss 0.0060 (0.0060)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2020-10-05 16:51:30]\n  Epoch: [003][200/391]   Time 0.087 (0.088)   Data 0.017 (0.017)   Loss 0.0035 (0.0110)   Prec@1 100.000 (99.670)   Prec@5 100.000 (100.000)   [2020-10-05 16:51:48]\n  **Train** Prec@1 99.692 Prec@5 99.998 Error@1 0.308 None\n\n==>>[2020-10-05 16:52:05] [Epoch=004/050] [Need: 00:26:33] [learning_rate=0.0100] [Best : Accuracy=0.00, Error=100.00]\n  Epoch: [004][000/391]   Time 0.204 (0.204)   Data 0.123 (0.123)   Loss 0.0130 (0.0130)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2020-10-05 16:52:05]\n  Epoch: [004][200/391]   Time 0.087 (0.088)   Data 0.016 (0.017)   Loss 0.0070 (0.0103)   Prec@1 100.000 (99.685)   Prec@5 100.000 (100.000)   [2020-10-05 16:52:22]\n  **Train** Prec@1 99.696 Prec@5 100.000 Error@1 0.304 None\n\n==>>[2020-10-05 16:52:39] [Epoch=005/050] [Need: 00:25:56] [learning_rate=0.0100] [Best : Accuracy=0.00, Error=100.00]\n  Epoch: [005][000/391]   Time 0.202 (0.202)   Data 0.122 (0.122)   Loss 0.0030 (0.0030)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2020-10-05 16:52:39]\n  Epoch: [005][200/391]   Time 0.088 (0.088)   Data 0.012 (0.017)   Loss 0.0493 (0.0118)   Prec@1 98.438 (99.627)   Prec@5 100.000 (99.996)   [2020-10-05 16:52:57]\n  **Train** Prec@1 99.660 Prec@5 99.998 Error@1 0.340 None\n\n==>>[2020-10-05 16:53:13] [Epoch=006/050] [Need: 00:25:20] [learning_rate=0.0100] [Best : Accuracy=0.00, Error=100.00]\n  Epoch: [006][000/391]   Time 0.205 (0.205)   Data 0.124 (0.124)   Loss 0.0035 (0.0035)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2020-10-05 16:53:13]\n  Epoch: [006][200/391]   Time 0.089 (0.088)   Data 0.016 (0.016)   Loss 0.0111 (0.0122)   Prec@1 99.219 (99.588)   Prec@5 100.000 (100.000)   [2020-10-05 16:53:31]\n  **Train** Prec@1 99.608 Prec@5 100.000 Error@1 0.392 None\n\n==>>[2020-10-05 16:53:48] [Epoch=007/050] [Need: 00:24:45] [learning_rate=0.0100] [Best : Accuracy=0.00, Error=100.00]\n  Epoch: [007][000/391]   Time 0.204 (0.204)   Data 0.122 (0.122)   Loss 0.0045 (0.0045)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2020-10-05 16:53:48]\n  Epoch: [007][200/391]   Time 0.085 (0.088)   Data 0.014 (0.016)   Loss 0.0145 (0.0103)   Prec@1 99.219 (99.728)   Prec@5 100.000 (100.000)   [2020-10-05 16:54:05]\n  **Train** Prec@1 99.696 Prec@5 100.000 Error@1 0.304 None\n\n==>>[2020-10-05 16:54:22] [Epoch=008/050] [Need: 00:24:09] [learning_rate=0.0100] [Best : Accuracy=0.00, Error=100.00]\n  Epoch: [008][000/391]   Time 0.206 (0.206)   Data 0.123 (0.123)   Loss 0.0038 (0.0038)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2020-10-05 16:54:22]\n  Epoch: [008][200/391]   Time 0.087 (0.089)   Data 0.016 (0.016)   Loss 0.0060 (0.0114)   Prec@1 100.000 (99.666)   Prec@5 100.000 (99.996)   [2020-10-05 16:54:40]\n", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "for kfscale in kfscale_list[10]:\n    print(kfscale.squeeze().numpy())", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "for kfscale_last in kfscale_list: \n    print(kfscale_last[-1].squeeze().numpy())", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "net=net.cpu()\nfor imd, (nam,module) in enumerate(net.named_modules()):\n    if isinstance(module, Kf_Conv2d):\n        module.score=module.bn.weight.data.abs()*(module.kfscale.data-(1-module.kfscale.data)).squeeze() \n      \n", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "for kfconv in kfconv_list:\n    kfconv.prune_rate=args.prune_rate\nfor imd, (nam,module) in enumerate(net.named_modules()):\n    if isinstance(module, Kf_Conv2d):\n        _,index=module.score.sort()\n        num_pruned_channel=int(module.prune_rate*module.score.shape[0])\n        \n        module.out_index=index[num_pruned_channel:]\n", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "\ndef recover_conv(net):\n\n    def _inject(modules):\n        keys = list(modules.keys())\n\n        for ik, k in enumerate(keys):\n            if isinstance(modules[k], Kf_Conv2d): #### Kf_Conv2d\u91cc\u9762\u6ca1\u6709k=0\u7684\n                modules[k] =Masked_Conv2d_bn(modules[k])\n                    \n            elif (not isinstance(modules[k], Kf_Conv2d)) and len(modules[k]._modules) > 0: # nn.Conv2d\u7684_modules\u7684\u957f\u5ea6\u4e3a0\uff0c\u4f46\u662fBiased_Conv2d\u7684\u957f\u5ea6\u4e3a1\n                _inject(modules[k]._modules)\n\n    _inject(net._modules)\nrecover_conv(net)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "net=net.cuda()\nfor input,target in train_loader:\n    net.train()\n    with torch.no_grad():\n        net(input)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "acc_before_ft,acc5_before_ft, loss_before_ft = validate(test_loader, net, criterion, log)\n\n\noptimizer_ft = torch.optim.SGD(net.parameters(), args.lr_ft, momentum=args.momentum,\n                            weight_decay=args.decay, nesterov=True)\n\nrecorder_ft = RecorderMeter(args.epochs_ft)\n\nrecorder_ft_top5=RecorderMeter(args.epochs_ft)\n\n\nfor epoch in range(0, args.epochs_ft):\n    current_learning_rate = adjust_learning_rate(optimizer_ft, epoch, lr_init=args.lr_ft)\n\n    need_hour, need_mins, need_secs = convert_secs2time(epoch_time.avg * (args.epochs_ft - epoch))\n    need_time = '[Need: {:02d}:{:02d}:{:02d}]'.format(need_hour, need_mins, need_secs)\n\n    print(\n        '\\n==>>{:s} [Epoch={:03d}/{:03d}] {:s} [learning_rate={:6.4f}]'.format(time_string(), epoch, args.epochs_ft,\n                                                                               need_time, current_learning_rate) \\\n        + ' [Best : Accuracy={:.2f}, Error={:.2f}]'.format(recorder_ft.max_accuracy(False),\n                                                           100 - recorder_ft.max_accuracy(False)))\n\n \n    train_acc, train_los = train(train_loader, net, criterion, optimizer_ft, epoch, log)\n\n   \n    val_acc_1,val_acc_5, val_los_1 = validate(test_loader, net, criterion, log)\n\n\n    is_best_ft = recorder_ft.update(epoch, train_los, train_acc, val_los_1, val_acc_1)\n\n    recorder_ft_top5.update(epoch, train_los, train_acc, val_los_1, val_acc_5)\n\n    save_checkpoint({\n        'epoch': epoch + 1,\n        'arch': args.arch,\n        'state_dict': net,\n        'recorder_ft': recorder_ft,\n        'optimizer': optimizer_ft.state_dict(),\n    }, is_best_ft, args.save_path, 'checkpoint_ft.pth.tar')\n\n    # measure elapsed time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time() ", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "print('top1:',recorder_ft.max_accuracy(False))", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "masked_conv_list=[]\nfor imd, (nam,module) in enumerate(net.named_modules()):\n    if isinstance(module, Masked_Conv2d_bn):\n        masked_conv_list.append((nam,module))\nif args.dataset=='imagenet':\n    for imd in range(len(masked_conv_list)):\n        \n        if 'conv2' in masked_conv_list[imd][0] or 'conv3' in masked_conv_list[imd][0]:\n            masked_conv_list[imd][1].in_index=masked_conv_list[imd-1][1].out_index\nelse:\n    for imd in range(len(masked_conv_list)):\n        \n        if 'conv_b' in masked_conv_list[imd][0]:\n            masked_conv_list[imd][1].in_index=masked_conv_list[imd-1][1].out_index", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "\n\nif args.dataset=='imagenet':\n    def pruning_conv( net):\n       \n        def _inject(modules):\n            keys = list(modules.keys())\n       \n            for ik, k in enumerate(keys):\n                if isinstance(modules[k], Masked_Conv2d_bn): \n                 \n                    if args.arch=='resnet18' or args.arch=='resnet34':\n                        if 'conv1' in k:\n                            modules[k] = Pruned_Conv2d_bn1(modules[k])\n                        elif 'conv2' in k:      \n                            modules[k] = Pruned_Conv2d_bn2(modules[k])\n                    else: ##### bottleneck\u7ed3\u6784\n                        if 'conv1' in k:\n                            modules[k] = Pruned_Conv2d_bn1(modules[k])\n                        elif 'conv2' in k:      \n                            modules[k] = Pruned_Conv2d_bn_middle(modules[k])\n                        elif 'conv3' in k:      \n                            modules[k] = Pruned_Conv2d_bn2(modules[k])\n\n                elif (not isinstance(modules[k], Kf_Conv2d)) and len(modules[k]._modules) > 0: \n                    _inject(modules[k]._modules)\n        _inject(net._modules)\n\nelse:\n    def pruning_conv( net):\n     \n        def _inject(modules):\n            keys = list(modules.keys())\n       \n            for ik, k in enumerate(keys):\n                if isinstance(modules[k], Masked_Conv2d_bn): \n                  \n                    if 'conv_a' in k:\n                        modules[k] = Pruned_Conv2d_bn1(modules[k])\n                    elif 'conv_b' in k:      \n                        modules[k] = Pruned_Conv2d_bn2(modules[k])\n\n                elif (not isinstance(modules[k], Kf_Conv2d)) and len(modules[k]._modules) > 0: \n                    _inject(modules[k]._modules)\n        _inject(net._modules)\npruning_conv(net)", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pytorch-1.0.0", "display_name": "Pytorch-1.0.0", "language": "python"}, "language_info": {"name": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}